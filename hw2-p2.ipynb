{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd4b5746c67b8f50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Problem 2 Knn & Adaboost**\n",
    "\n",
    "In this part, you'll be working with KNN and AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fee3162f4d5bcd8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 0) Loading Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4ce3395fb6fef52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "# set a seed for reproducibility\n",
    "random_seed = 25\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# We need to ignore FutureWarnings due to a bug in our version of sklearn\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a794107521856db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1) Twitter Sentiment Analysis using KNN\n",
    "\n",
    "[Sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis) is the study of how we can systematically identify and quantify sentiment of a given segment of text. In this problem, you will be using a reduced version the [Sentiment140](https://www.kaggle.com/datasets/kazanova/sentiment140) dataset to build a classifier that will determine if a tweet expressive positive or negative sentiment. The original dataset has sentiment ratings ranging from 0 (very negative) to 4 (very positive), as well as inbetween values with 2 being neutral. However, for simplicity, we've only given you explicitly positive or negative tweets.\n",
    "\n",
    "**WARNING:** This is *real* data from *real* people from Twitter. This means that if you browse through the actual text (which you are not required to do so), you might see offensive, toxic, and potentially triggering language. [Toxicity Detection](https://aclanthology.org/2020.acl-main.396/) is an ongoing field of research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45c873099b66450c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's take a look at our data, and what attributes we have.\n",
    "\n",
    "* **polarity**: The assumed polarity of the tweet. For this subset, we're only considering positive and negative tweets, no neutrality.\n",
    "* **id**: The tweet ID.\n",
    "* **date**: The date the tweet was posted.\n",
    "* **query**: The search term used in order to find tweets of a certain topic.\n",
    "* **text**: The actual text of the tweet.\n",
    "\n",
    "For now, we only consider the **polarity** and **text** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af2e6d8897dc4255",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>639736</td>\n",
       "      <td>0</td>\n",
       "      <td>1881528306</td>\n",
       "      <td>Fri May 22 04:54:30 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ClareMacG</td>\n",
       "      <td>where is he? hmmmm he didnt even reply to me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228095</td>\n",
       "      <td>0</td>\n",
       "      <td>1759081303</td>\n",
       "      <td>Sun May 10 18:25:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jaredhaha</td>\n",
       "      <td>family guy sucks tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>689126</td>\n",
       "      <td>0</td>\n",
       "      <td>2322274292</td>\n",
       "      <td>Wed Jun 24 22:20:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>spazzyyarn</td>\n",
       "      <td>@jesus_iscomin  I am so sorry, that sucks!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372153</td>\n",
       "      <td>0</td>\n",
       "      <td>1693569517</td>\n",
       "      <td>Sun May 03 22:59:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>missprettylady</td>\n",
       "      <td>goin to bed...definitly didn't study like i wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>365761</td>\n",
       "      <td>0</td>\n",
       "      <td>2244313762</td>\n",
       "      <td>Fri Jun 19 14:35:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jojoe777</td>\n",
       "      <td>just was at the hospital, long story made shor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  polarity          id                          date     query  \\\n",
       "0      639736         0  1881528306  Fri May 22 04:54:30 PDT 2009  NO_QUERY   \n",
       "1      228095         0  1759081303  Sun May 10 18:25:07 PDT 2009  NO_QUERY   \n",
       "2      689126         0  2322274292  Wed Jun 24 22:20:07 PDT 2009  NO_QUERY   \n",
       "3      372153         0  1693569517  Sun May 03 22:59:23 PDT 2009  NO_QUERY   \n",
       "4      365761         0  2244313762  Fri Jun 19 14:35:02 PDT 2009  NO_QUERY   \n",
       "\n",
       "             user                                               text  \n",
       "0       ClareMacG  where is he? hmmmm he didnt even reply to me t...  \n",
       "1       jaredhaha                          family guy sucks tonight   \n",
       "2      spazzyyarn         @jesus_iscomin  I am so sorry, that sucks!  \n",
       "3  missprettylady  goin to bed...definitly didn't study like i wa...  \n",
       "4        jojoe777  just was at the hospital, long story made shor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./hw2_p3.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-15001b5e2db73bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity\n",
       "0    20000\n",
       "4    20000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our disribution of polarity\n",
    "# 4 means postive sentiment\n",
    "# 0 means negative sentiment\n",
    "train_data.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5327894d81868004",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1) Example: Brief Introduction to tf-idf\n",
    "\n",
    "Read through and run the following example, and answer the question at the end.\n",
    "\n",
    "In information retreival [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (*term frequency â€“ inverse document frequency*) is a metric that represents how \"important\" a word is to a corpus of text. While we won't go into detail about how it works, essentially all you need to know is that it balances two metrics.\n",
    "\n",
    "**Term Frequency**: Is exactly what one would expect, it is the the frequency at which a word is present in a corpus of text. A word with a higher term-frequency score appears much more in the corpus compared to one with a low term frequency.\n",
    "\n",
    "**Inverse Document Frequency**: If we only used term frequency, common words like \"the\" or \"and\" would have a high score, even though they don't give us that much information since they are present in every document. *Inverse Document Frequency* is a metric of how much \"information\" a word provides, and if a word is common or rare across all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b74f76425851151",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### tf-idf with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4787c5e461ffd63d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?'\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6dc0a0bd2457d87c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The tf-idf vectorizer's `fit_transform` method returns a NxM matrix. `N` is the number of documents (sentences) you have in your corpus, and `M` is the number of unique words in your corpus. Item `n`x`m` is how important word `m` is to document `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]\n",
      " [0.     0.6876 0.     0.2811 0.     0.5386 0.2811 0.     0.2811]\n",
      " [0.5118 0.     0.     0.2671 0.5118 0.     0.2671 0.5118 0.2671]\n",
      " [0.     0.4698 0.5803 0.3841 0.     0.     0.3841 0.     0.3841]]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the tf-idf matrix\n",
    "np.set_printoptions(precision=4)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that if we try and print X directly, we get an overview saying that X is a \"sparse matrix\".\n",
    "# In very large corpi with many unique words, a lot of row entries are going to consist of majority zeros\n",
    "# Thus numpy saves theses in a special compressed sparse format\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next let's see what word each column corresponds to:\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5bd2abaa3f0ad819",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at the tf-idf vectors for two different documents.\n",
    "\n",
    "**Note**: `dic(zip(A, B))` in pyton makes a dictionary out of a list of keys (A) and values (B). This just makes it easier to view each term with it's corresponding TFIDF value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3627097c25aa7b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first document.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.0,\n",
       " 'document': 0.46979138557992045,\n",
       " 'first': 0.5802858236844359,\n",
       " 'is': 0.38408524091481483,\n",
       " 'one': 0.0,\n",
       " 'second': 0.0,\n",
       " 'the': 0.38408524091481483,\n",
       " 'third': 0.0,\n",
       " 'this': 0.38408524091481483}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus[0])\n",
    "dict(zip(vectorizer.get_feature_names_out(),X.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b72ce213380d8220",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is the second document.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.0,\n",
       " 'document': 0.6876235979836938,\n",
       " 'first': 0.0,\n",
       " 'is': 0.281088674033753,\n",
       " 'one': 0.0,\n",
       " 'second': 0.5386476208856763,\n",
       " 'the': 0.281088674033753,\n",
       " 'third': 0.0,\n",
       " 'this': 0.281088674033753}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus[1])\n",
    "dict(zip(vectorizer.get_feature_names_out(),X.toarray()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27d6d2b55e8301b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take a look at the tf-idf vectors for both of these sentences and answer the following questions:\n",
    "1. Why is the value for the term \"is\" higher in document1 than document2?\n",
    "2. Why is the value for the term \"document\" higher in document2 than document1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Here**\n",
    "\n",
    "**1. Why is the value for the term \"is\" higher in document1 than document2?**\n",
    "\n",
    "This may be because of the difference in document length. Since there are the same instance of \"is\" in both document1 and document2, the only difference would be the length of the documents. Document1 is shorter than document 2 by one word, meaning that the word \"is\" may have a higher impact/value due to the fact that it has an influence of 1/5 in document1 instead of 1/6 in document 2. This calculation may be the result of the normalization techniques applied in the TF_IDF metric.\n",
    "   \n",
    "**2. Why is the value for the term \"document\" higher in document2 than document1?**\n",
    "\n",
    "This may be due to the fact that document2 have two instances of the term \"document\" instead of one instance in document1. Since there are two instances in document2, the term frequency part of the TF-IDF metric may have scored it higher than document1's \"document\" since document1 only have one instance of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5d6dd2a1fd26f181",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2) tf-idf on Twitter\n",
    "\n",
    "Now, before we build a classifier, let's just try and see what the nearest neighbors of a specified message are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-247861d851d2a5e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Get our text\n",
    "corpus = train_data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a3dacaeb29d8337",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run our transform\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tfidf_matrix = tf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b47ac9333d7a0f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x50209 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 476467 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the size of our matrix\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcc831ed367bedc1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's fit the nearest neighbors tree! Please use [NearestNeighbors](https://scikit-learn.org/stable/modules/neighbors.html) from sklearn library\n",
    "\n",
    "NOTE: fit the nearest neighbors tree (with **five** neighbors) on _**\"tfidf_matrx\"**_ we got from above, and return the model as _**\"nbrs\"**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "nn",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "# TODO\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=5)\n",
    "nbrs.fit(tfidf_matrix)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "nn-public",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(nbrs.n_features_in_ == 50209)\n",
    "assert(nbrs.n_samples_fit_ == 40000)\n",
    "assert(nbrs.get_params()['n_neighbors'] == 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9db51af033047d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now run custom sentences and see what sentences in the corpus are \"closest\" to what we put in. Try a few and see what shows up! In addition to this, you can change the `n_neighbors` param and get more queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a42677ceaef33de1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8386</th>\n",
       "      <td>230301</td>\n",
       "      <td>0</td>\n",
       "      <td>2234441446</td>\n",
       "      <td>Thu Jun 18 23:03:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Cheeseter550</td>\n",
       "      <td>@ThisFails man that sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14483</th>\n",
       "      <td>1886</td>\n",
       "      <td>0</td>\n",
       "      <td>2241488966</td>\n",
       "      <td>Fri Jun 19 11:00:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Johnn_G</td>\n",
       "      <td>The weather sucks. And I'm hungry, but there's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10417</th>\n",
       "      <td>147250</td>\n",
       "      <td>0</td>\n",
       "      <td>2015648053</td>\n",
       "      <td>Wed Jun 03 05:11:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>renofeliz</td>\n",
       "      <td>why the weather is so crap today?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11601</th>\n",
       "      <td>560236</td>\n",
       "      <td>0</td>\n",
       "      <td>1980392498</td>\n",
       "      <td>Sun May 31 06:36:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MissCammie</td>\n",
       "      <td>oooh man.. being ill sucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>415455</td>\n",
       "      <td>0</td>\n",
       "      <td>1961049897</td>\n",
       "      <td>Fri May 29 08:54:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ArtyBloodyFarty</td>\n",
       "      <td>that just sucks!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  polarity          id                          date  \\\n",
       "8386       230301         0  2234441446  Thu Jun 18 23:03:45 PDT 2009   \n",
       "14483        1886         0  2241488966  Fri Jun 19 11:00:48 PDT 2009   \n",
       "10417      147250         0  2015648053  Wed Jun 03 05:11:31 PDT 2009   \n",
       "11601      560236         0  1980392498  Sun May 31 06:36:33 PDT 2009   \n",
       "7872       415455         0  1961049897  Fri May 29 08:54:33 PDT 2009   \n",
       "\n",
       "          query             user  \\\n",
       "8386   NO_QUERY     Cheeseter550   \n",
       "14483  NO_QUERY          Johnn_G   \n",
       "10417  NO_QUERY        renofeliz   \n",
       "11601  NO_QUERY       MissCammie   \n",
       "7872   NO_QUERY  ArtyBloodyFarty   \n",
       "\n",
       "                                                    text  \n",
       "8386                          @ThisFails man that sucks   \n",
       "14483  The weather sucks. And I'm hungry, but there's...  \n",
       "10417                 why the weather is so crap today?   \n",
       "11601                        oooh man.. being ill sucks   \n",
       "7872                                   that just sucks!   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs = [\"Man, the weather today SUCKS!!!\"]\n",
    "test_docs = tf.transform(test_docs)\n",
    "distances, indicies = nbrs.kneighbors(test_docs)\n",
    "train_data.iloc[indicies[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12a84f0eac5cc6b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.065  1.0657 1.076  1.0781 1.0874]]\n"
     ]
    }
   ],
   "source": [
    "# As a bonus, show our distances\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0c7cdf55f67b06d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now investigate:\n",
    "1. Try manually classifying the tweet \"Wow, this is so cool!\" What are the classes of the neighbors? How would a 5-NN classifier classify that tweet?\n",
    "2. Can you think of a tweet that might fool this classifier? For example, how would it do with sarcasm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-654053a2955a0089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will continue working witht this dataset in hw2-p3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e38e9e04d7b092b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2) AdaBoost\n",
    "\n",
    "In this exercise, you'll be learning how to use [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), as well as vizualize decision boundries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2e82c5604cce2ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1) Exmple: Decision Tree Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-643efca93cb2ef42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Read the breast cancer dataset and translate to pandas dataframe\n",
    "bc_sk = datasets.load_breast_cancer()\n",
    "# Note that the \"target\" attribute is species, represented as an integer\n",
    "bc_data = pd.DataFrame(data= np.c_[bc_sk['data'], bc_sk['target']],columns= list(bc_sk['feature_names'])+['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3a7764bf66b2406b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# The fraction of data that will be test data\n",
    "test_data_fraction = 0.10\n",
    "\n",
    "bc_features = bc_data.iloc[:,0:-1]\n",
    "bc_labels = bc_data[\"target\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(bc_features, bc_labels, test_size=test_data_fraction,  random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41c236bfc6099552",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's have a baseline non-boosted decision tree to compare against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e3cf16aea05cf2bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "gini_tree = DecisionTreeClassifier(criterion = \"gini\", random_state=random_seed).fit(X=X_train, y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d5baa7e1ea2a864d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predicted_y = gini_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3257c7df126745f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85        20\n",
      "         1.0       0.92      0.92      0.92        37\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.88      0.88      0.88        57\n",
      "weighted avg       0.89      0.89      0.89        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted_y,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9cf042160ae42191",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  3],\n",
       "       [ 3, 34]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predicted_y,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Adaboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c930e798d27e97cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's get boosting with the [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). The default estimator for AdaBoost is a *decision stump*. (Remember: a decision stump is simply a decision tree with a height of 1).\n",
    "\n",
    "* The `n_estimators` parameter is the number of base models in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "adaboost",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=20, random_state=25)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=20, random_state=25)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=20, random_state=25)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# TODO: Create and train an AdaBoostClassifier with 20 estimators on the X_train and Y_train data\n",
    "# Note: Make sure to use random_state=random_seed\n",
    "ada_model = None\n",
    "### BEGIN ANSWER\n",
    "\n",
    "ada_model = AdaBoostClassifier(n_estimators=20, random_state=random_seed)\n",
    "ada_model.fit(X_train, Y_train)\n",
    "\n",
    "### END ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0f584b9b4cebda33",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "np.testing.assert_almost_equal(accuracy_score(ada_model.predict(X_test), Y_test), 0.9473684210526315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5065de2c51aa8c2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predicted_y = ada_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-75ac58d9033a2843",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.95      0.92        19\n",
      "         1.0       0.97      0.95      0.96        38\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.94      0.95      0.94        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predicted_y,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16364b75ccc14537",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18,  1],\n",
       "       [ 2, 36]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predicted_y,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-82768f17f1b3dd4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As we can see, the boosted model performs better than a full decision tree, even though it only uses some decision stumps."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
